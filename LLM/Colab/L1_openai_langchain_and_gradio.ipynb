{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/phuonghoathu/nothing1988nevergive/blob/main/L1_openai_langchain_and_gradio.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "api_key = \"sk-...\""
      ],
      "metadata": {
        "id": "1T9Mut_Pxs2F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Phần 1: OpenAI và Gradio"
      ],
      "metadata": {
        "id": "GIEsm-8hwig8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Bước 1: Cài đặt OpenAI API và Gradio"
      ],
      "metadata": {
        "id": "yG23mlZtXLV2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WhOQp8SVUNaj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bdc7403a-4ed9-4bc2-e6e3-bbb5fa5191ef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.0/17.0 MB\u001b[0m \u001b[31m44.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.1/92.1 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m308.2/308.2 kB\u001b[0m \u001b[31m26.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m59.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.8/60.8 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.5/71.5 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for ffmpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install -U --quiet openai gradio"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Bước 2: Define các thư viện cần thiết"
      ],
      "metadata": {
        "id": "k3VNg72iXt3L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "import gradio as gr\n",
        "\n",
        "client = OpenAI(api_key=api_key)"
      ],
      "metadata": {
        "id": "y0OeHQy6XUvm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Bước 3: Define function predict và khởi chạy\n"
      ],
      "metadata": {
        "id": "GVbHjcnYY9jd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(message, history):\n",
        "    history_openai_format = []\n",
        "    for human, assistant in history:\n",
        "        history_openai_format.append({\"role\": \"user\", \"content\": human })\n",
        "        history_openai_format.append({\"role\": \"assistant\", \"content\":assistant})\n",
        "    history_openai_format.append({\"role\": \"user\", \"content\": message})\n",
        "\n",
        "    response = client.chat.completions.create(model='gpt-3.5-turbo',\n",
        "    messages= history_openai_format,\n",
        "    temperature=1.0,\n",
        "    stream=True)\n",
        "\n",
        "    partial_message = \"\"\n",
        "    for chunk in response:\n",
        "        if chunk.choices[0].delta.content is not None:\n",
        "              partial_message = partial_message + chunk.choices[0].delta.content\n",
        "              yield partial_message\n",
        "\n",
        "gr.ChatInterface(predict).launch()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 648
        },
        "id": "Yp7gbCxqY69j",
        "outputId": "e266b336-c63b-4990-bd07-138da567be4f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting queue=True in a Colab notebook requires sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Running on public URL: https://c456b14b7b544bb456.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://c456b14b7b544bb456.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "fP2gnrMLwrAl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Phần 2: Giới Thiệu LangChain + Tạo phiên bản số của bạn"
      ],
      "metadata": {
        "id": "Za2MlSeGwwO7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U --quiet langchain langchain_openai"
      ],
      "metadata": {
        "id": "OyZ77Unwww-U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.messages import HumanMessage, SystemMessage, AIMessage\n",
        "from langchain_core.prompts.chat import (\n",
        "    ChatPromptTemplate,\n",
        "    HumanMessagePromptTemplate,\n",
        "    SystemMessagePromptTemplate,\n",
        ")\n",
        "import gradio as gr\n",
        "from langchain_openai import ChatOpenAI"
      ],
      "metadata": {
        "id": "KR2z7Jo5xJUG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chat = ChatOpenAI(temperature=0, openai_api_key=api_key)"
      ],
      "metadata": {
        "id": "za5x3pMLxSwv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "default = \"\"\"Bạn là một phiên bản ảo của Trấn Thành. Trấn Thành là một MC nổi tiếng với tính tình hài hước, và được người dân Việt Nam yêu quý.\n",
        "Một số điều lưu ý về Trấn Thành như sau:\n",
        "- Trấn Thành ưu tiên sự riêng tư, đừng hỏi những thứ quá cá nhân về Trấn Thành.\n",
        "- Trấn Thành thích được nói về những bài học cuộc sống cho mọi người học hỏi.\"\"\"\n",
        "\n",
        "your_prompt = \"\"\"YOUR_PROMPT\"\"\""
      ],
      "metadata": {
        "id": "yLhcxmcczFLm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(message, history):\n",
        "    history_list = []\n",
        "    history_list.append(SystemMessage(content=default))\n",
        "    for human, assistant in history:\n",
        "        history_list.append(HumanMessage(content=human))\n",
        "        history_list.append(AIMessage(content=assistant))\n",
        "    history_list.append(HumanMessage(content=message))\n",
        "\n",
        "    partial_message = ''\n",
        "    for chunk in chat.stream(history_list):\n",
        "      if chunk.content is not None:\n",
        "        partial_message = partial_message + chunk.content\n",
        "        yield partial_message\n",
        "\n",
        "\n",
        "gr.ChatInterface(predict).launch(debug=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eLTzmYP8yiW6",
        "outputId": "53cde7ad-f292-46af-adaf-403115c8869b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting queue=True in a Colab notebook requires sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "Running on public URL: https://ad2f68023493c745e0.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://ad2f68023493c745e0.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keyboard interruption in main thread... closing server.\n",
            "Killing tunnel 127.0.0.1:7861 <> https://ad2f68023493c745e0.gradio.live\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ee89bogS0zeT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}